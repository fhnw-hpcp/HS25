{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c113d32",
   "metadata": {},
   "source": [
    "![GPU ecosystem](img/02_GPU_Ecosystem/Folie1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a98d083-4bfc-41c9-8084-3d7635554f5c",
   "metadata": {},
   "source": [
    "![GPU Ecosystem](img/13_ecosystem.png)\n",
    "(Image credits: https://blogs.nvidia.com/blog/what-is-cuda-2/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac421c82-61bc-44fa-a6fd-5b7f126d9ad5",
   "metadata": {},
   "source": [
    "### CuPy\n",
    "CuPy provides a NumPy-compatible API, with its backend implemented in CUDA C++. This design enables users already familiar with NumPy to seamlessly leverage GPU acceleration by simply replacing the import statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5882097f-ec71-46f7-8ae7-6832a66fe342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NVSHARE][INFO]: Using CUDA device with id 0\n",
      "[NVSHARE][INFO]: Using scheduler socket path: /var/run/nvshare/scheduler0.sock\n",
      "[NVSHARE][INFO]: Successfully initialized nvshare GPU\n",
      "[NVSHARE][INFO]: Client ID = d581a26579178066\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "\n",
    "cp_stream = cp.cuda.Stream()\n",
    "cp_stream.use()\n",
    "\n",
    "# We will use this call to synchronize async calls of cupy. \n",
    "cp_stream.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7648c166-8219-44bd-a444-408291dad473",
   "metadata": {},
   "source": [
    "We will use `cp_stream.synchronize()` to ensure that asynchronous GPU calls are completed before moving on.  \n",
    "At this point, we will not go into the details of what a CUDA stream is or how it works.  \n",
    "\n",
    "In many examples you will see online, synchronization is done with `Stream.null.synchronize()`, which waits on the **default stream**. This approach is fine if you are the only one using the GPU.  \n",
    "In our environment, however, the GPUs are shared. To manage this fairly and safely, we use some additional abstractions under the hood. For this reason, we explicitly call `cp_stream.synchronize()` in our examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a19224f5-61f1-409d-be4a-bc7f0fc58405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CuPy result z (on GPU): [1.0000e+00 3.0000e+00 5.0000e+00 ... 1.9995e+04 1.9997e+04 1.9999e+04]\n",
      "Type of z: <class 'cupy.ndarray'>\n",
      "Retrieve z to host as NumPy: [1.0000e+00 3.0000e+00 5.0000e+00 ... 1.9995e+04 1.9997e+04 1.9999e+04]\n"
     ]
    }
   ],
   "source": [
    "# Create a CuPy array of 10'000 elements and perform some operations\n",
    "x = cp.arange(10_000, dtype=cp.float32)        # array([0., 1., 2., ...], dtype=float32) on GPU\n",
    "y = cp.ones(10_000, dtype=cp.float32)          # array([1., 1., ...], dtype=float32) on GPU\n",
    "z = x * 2 + y                                  # elementwise operations on GPU\n",
    "print(\"CuPy result z (on GPU):\", z)            # This is a cupy.ndarray\n",
    "print(\"Type of z:\", type(z))\n",
    "print(\"Retrieve z to host as NumPy:\", cp.asnumpy(z))  # convert to NumPy array for printing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3077014e-5d97-440c-b3cd-88abdfd836fc",
   "metadata": {},
   "source": [
    "When you run this, you should see that z is a CuPy array object, but converting it to a NumPy array yields the expected result (e.g., [1., 3., 5., ...] for the above computation). The syntax and results are just like NumPy, but all calculations took place on the GPU.\n",
    "\n",
    "We can also demonstrate some common mathematical operations and verify that CuPy’s results match NumPy’s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb09547a-446f-44ff-bb68-7ccd2866904b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy exp: [1.         1.28402542 1.64872127 2.11700002 2.71828183]\n",
      "CuPy exp: [1.         1.28402542 1.64872127 2.11700002 2.71828183]\n",
      "CuPy matches NumPy for exp computation.\n"
     ]
    }
   ],
   "source": [
    "data_cpu = np.linspace(0, 1, 5)\n",
    "data_gpu = cp.linspace(0, 1, 5)\n",
    "print(\"NumPy exp:\", np.exp(data_cpu))\n",
    "print(\"CuPy exp:\", cp.exp(data_gpu))\n",
    "\n",
    "# Verify they match (after bringing the CuPy result to host)\n",
    "assert np.allclose(np.exp(data_cpu), cp.asnumpy(cp.exp(data_gpu)))\n",
    "print(\"CuPy matches NumPy for exp computation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba43e0d-0f28-48bd-977d-76e6d6bca910",
   "metadata": {},
   "source": [
    "This shows how you can use `cp.exp`, `cp.sin`, `cp.log`, etc., just like their NumPy counterparts. Most universal functions (ufuncs) are supported by CuPy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205471f0-a043-4336-98cd-4cfbe62ba369",
   "metadata": {},
   "source": [
    "#### Memory transfers\n",
    "Note that creating data_gpu from scratch on the GPU (as above with `cp.linspace`) avoids any CPU-GPU copy. If instead you did data_gpu = cp.asarray(data_cpu), it would transfer the NumPy array to GPU memory. It’s important in HPC to minimize host-device transfers because the PCIe bus is relatively slow.\n",
    "**Try to perform as much computation on the GPU as possible once the data is there, and only bring results back to the host when needed.**\n",
    "\n",
    "One of the strengths of CuPy lies in its highly integrated memory system. Data movement between host (CPU) and device (GPU) memory is managed efficiently, reducing overhead and enabling seamless interoperability with other Python frameworks. In particular, **NumPy** arrays can be transferred to and from CuPy with minimal effort, and CuPy arrays can also interoperate directly with **Numba's CUDA** extension without explicit data copies.\n",
    "\n",
    "This tight integration allows researchers and developers to combine the ease of NumPy, the GPU acceleration of CuPy, and the just-in-time compilation capabilities of Numba in a single workflow. Below are some common examples of casting between these frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcbd3970-5af0-49bc-91bd-5739f194cd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy -> CuPy\n",
    "array_np = np.array([1, 2, 3])\n",
    "array_cp = cp.asarray(array_np)\n",
    "\n",
    "# CuPy -> NumPy\n",
    "array_np = cp.asnumpy(array_cp)\n",
    "\n",
    "# CuPy -> Numba (DeviceNDArray)\n",
    "array_numba = cuda.as_cuda_array(array_cp)\n",
    "\n",
    "# Numba -> CuPy\n",
    "array2_cp = cp.asarray(array_numba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df35a1ce-de5b-45a8-ac8d-339bb4071a45",
   "metadata": {},
   "source": [
    "#### CuPy for FFT and Linear Algebra\n",
    "\n",
    "Beyond basic arithmetic, CuPy also supports advanced numerical routines. For example, Fast Fourier Transforms (FFT) are available via cupy.fft (using NVIDIA’s cuFFT library under the hood), and linear algebra routines (e.g. matrix multiplication, inversion, SVD) via cupy.linalg (using cuBLAS, cuSolver, etc.). This means you can accelerate signal processing and linear algebra workloads with minimal changes to your code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc6a7ff-c364-406f-acb8-96001f25f44c",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "\n",
    "Create an example using the Fast Fourier Transform (FFT):\n",
    "\n",
    "1. Generate a large synthetic signal (e.g., a sine wave or a combination of waves)\n",
    "2. Compute its frequency spectrum on the CPU using NumPy  \n",
    "3. Compute the same frequency spectrum on the GPU using CuPy  \n",
    "4. Compare the two results to verify that they match\n",
    "5. Compare the runtime of the two implementations\n",
    "6. Compare the total runtime (including H2D and D2H) to the kernel runtime only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0870b998-6986-4324-bf7d-e2443b6f4291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between CPU FFT and GPU FFT: 3.753457592312974e-10\n",
      "CPU implementation: 34.5 ms ± 352 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "GPU kernel:         669 μs ± 774 ns per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "GPU implementation: 3.75 ms ± 8.45 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "#ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2ae82e-575e-42cb-b886-03cea0a6a275",
   "metadata": {},
   "source": [
    "For linear algebra, CuPy’s linalg module includes functions like `cp.linalg.inv` (matrix inverse), `cp.linalg.svd`, `cp.linalg.solve` (solve linear systems), and of course matrix multiplication can be done with the `@` operator or `cp.dot`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ce4086-a72c-4dd4-bc7e-a1c6996a1c37",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "Use CuPy to solve a system of linear equations:\n",
    "\n",
    "1. Create a large random matrix `A` and a random vector `b`.  \n",
    "2. Solve the system \\(Ax = b\\) on the GPU using `cp.linalg.solve`.  \n",
    "3. Solve the same system on the CPU using `np.linalg.solve`.  \n",
    "4. Compare the runtime of both approaches.  \n",
    "5. Verify that the solutions are consistent (e.g., by checking the maximum absolute difference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7c48a4d-10a1-4607-8746-edb06d4a2729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max difference between CPU and GPU results: 3.70e-04\n",
      "CPU implementation: 281 ms ± 723 μs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "GPU kernel:         5.98 ms ± 1.84 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "#ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a586fc-b21c-45be-8921-e743b6d72356",
   "metadata": {},
   "source": [
    "### Writing Custom CUDA Kernels with CuPy (Advanced)\n",
    "\n",
    "This section is optional, since you have learned to write custom GPU kernels with Numba in a previous notebook. But it’s good to know that CuPy also allows custom kernels written in CUDA C. This shows how CuPy allows going “closer to the metal” when necessary, by embedding CUDA C code. In practice, many problems can be solved with CuPy’s high-level functions alone, but if you have an existing CUDA kernel or need something very custom, CuPy can incorporate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "faec11b9-39f5-4799-8d2c-5a86cc0aaeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom kernel produced correct results.\n"
     ]
    }
   ],
   "source": [
    "# A simple example of a custom CUDA kernel using CuPy\n",
    "kernel_code = r\"\"\"\n",
    "extern \"C\" __global__\n",
    "void add_arrays(const float* x, const float* y, float* out, int n) {\n",
    "    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    if(idx < n) {\n",
    "        out[idx] = x[idx] + y[idx];\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "# Compile the kernel\n",
    "module = cp.RawModule(code=kernel_code, name_expressions=[\"add_arrays\"])\n",
    "add_arrays_kernel = module.get_function(\"add_arrays\")\n",
    "\n",
    "# Prepare data\n",
    "n = 1000000\n",
    "x = cp.random.random(n, dtype=cp.float32)\n",
    "y = cp.random.random(n, dtype=cp.float32)\n",
    "out = cp.empty(n, dtype=cp.float32)\n",
    "\n",
    "# Launch kernel (grid = ceil(n/256) blocks, block = 256 threads)\n",
    "threads_per_block = 256\n",
    "blocks = (n + threads_per_block - 1) // threads_per_block\n",
    "add_arrays_kernel((blocks,), (threads_per_block,), (x, y, out, n))\n",
    "cp_stream.synchronize()\n",
    "\n",
    "# Verify correctness\n",
    "assert cp.allclose(out, x + y)\n",
    "print(\"Custom kernel produced correct results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d12989-10b0-44b8-a213-ed4fb70ce5a5",
   "metadata": {},
   "source": [
    "### RAPIDS: GPU DataFrames and Machine Learning (cuDF, cuML, etc.)\n",
    "\n",
    "RAPIDS is an open-source suite of libraries led by NVIDIA that brings the familiar data science stack (pandas, SQL, scikit-learn, etc.) to the GPU. The key idea is to provide GPU-accelerated DataFrames, machine learning algorithms, and more, with APIs that mirror popular Python libraries, allowing users to leverage GPUs with minimal code changes. RAPIDS is built on top of the CUDA libraries. Two primary components of RAPIDS we will explore are cuDF and cuML:\n",
    "\n",
    "cuDF – a GPU DataFrame library that provides a pandas-like API for loading, filtering, joining, grouping, and analyzing tabular data on the GPU. You can think of cuDF as “pandas on CUDA”. It uses a C++ GPU library called libcudf under the hood for performance.\n",
    "\n",
    "cuML – a suite of GPU-accelerated machine learning algorithms (part of RAPIDS) that mirror the scikit-learn API. It offers algorithms like linear regression, logistic regression, PCA, clustering (e.g., K-Means, DBSCAN), random forests, etc., all running on GPUs.\n",
    "\n",
    "RAPIDS also includes cuGraph (GPU graph analytics with a NetworkX-like API), cuSignal (GPU signal processing), cuxFilter (GPU-accelerated dashboards), and others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693543c5-5590-4635-b9b6-4ac0dd32ce4f",
   "metadata": {},
   "source": [
    "⚠️ **Important:** Please switch to the **`hpcp_rapids`** kernel.  \n",
    "Managing all required packages for this course in a single, cross-compatible environment is challenging, so we provide this preconfigured kernel for you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ba9fac4-9b0f-4554-b717-6162d689d6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuDF DataFrame:\n",
      "    id  value\n",
      "0   1   10.0\n",
      "1   2   15.5\n",
      "2   3    7.2\n",
      "3   4   23.3\n",
      "4   5   42.0\n",
      "Compute summary stats (like pandas describe):\n",
      "              id      value\n",
      "count  5.000000   5.000000\n",
      "mean   3.000000  19.600000\n",
      "std    1.581139  13.947939\n",
      "min    1.000000   7.200000\n",
      "25%    2.000000  10.000000\n",
      "50%    3.000000  15.500000\n",
      "75%    4.000000  23.300000\n",
      "max    5.000000  42.000000\n"
     ]
    }
   ],
   "source": [
    "import cudf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a cuDF DataFrame from Python data\n",
    "df = cudf.DataFrame({\n",
    "    'id': [1, 2, 3, 4, 5],\n",
    "    'value': [10.0, 15.5, 7.2, 23.3, 42.0]\n",
    "})\n",
    "print(\"cuDF DataFrame:\\n\", df)\n",
    "print(\"Compute summary stats (like pandas describe):\\n\", df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cec9520-3236-4eca-ad03-e3a124e99235",
   "metadata": {},
   "source": [
    "This should display a DataFrame similar to how pandas would (with an index and the data for id and value columns). The df.describe() will compute summary statistics on the GPU. You can already see the API is pandas-like. Many pandas methods (such as `df.head()`, `df.tail()`, `df.mean()`, etc.) are available in cuDF.\n",
    "\n",
    "Now, let’s do something more substantial with cuDF. We’ll generate a large random dataset and perform some typical data analysis tasks on GPU: filtering, arithmetic, grouping, and aggregation. We will also compare the performance with pandas to highlight the benefit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7663886d-adb7-49d2-90d5-ddb834cbc147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a large random dataset\n",
    "N = 1_000_000  # one million rows\n",
    "# Using NumPy to generate data, then we'll transfer to cuDF\n",
    "age = np.random.randint(18, 90, size=N)            # random ages between 18 and 90\n",
    "income = np.random.random(size=N) * 100000         # random income between 0 and 100k\n",
    "# Create a pandas DataFrame (just to compare, optional)\n",
    "pdf = pd.DataFrame({'age': age, 'income': income})\n",
    "\n",
    "# Create a cuDF DataFrame from the NumPy arrays\n",
    "gdf = cudf.DataFrame({\n",
    "    'age': age,       # cudf can accept numpy arrays, it will copy to GPU\n",
    "    'income': income\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bfd6e40-5a19-4248-8909-70a87c2f0a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people over 65: 333448\n",
      "   age        income   income_k\n",
      "0   55  56036.257305  56.036257\n",
      "1   26  82063.073881  82.063074\n",
      "2   30  94068.201321  94.068201\n",
      "3   27  17022.360668  17.022361\n",
      "4   22  88255.036825  88.255037\n",
      "Average income by age decade: age_decade\n",
      "40    50124.512709\n",
      "10    50400.116154\n",
      "20    49887.161590\n",
      "70    50054.429544\n",
      "80    50045.276308\n",
      "30    49958.066663\n",
      "50    50180.339086\n",
      "60    49880.791125\n",
      "Name: income, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 1. Filtering: find how many people are over 65 years old\n",
    "num_over_65 = gdf[gdf.age > 65].shape[0]\n",
    "print(\"Number of people over 65:\", num_over_65)\n",
    "\n",
    "# 2. Arithmetic: add a new column for income in thousands\n",
    "gdf['income_k'] = gdf['income'] / 1000.0\n",
    "print(gdf.head())\n",
    "\n",
    "# 3. Group by: compute average income by age group (decade of age)\n",
    "gdf['age_decade'] = (gdf['age'] // 10) * 10\n",
    "avg_income_by_decade = gdf.groupby('age_decade').income.mean()\n",
    "print(\"Average income by age decade: \", end=\"\")\n",
    "print(avg_income_by_decade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91ae32d9-9be5-47db-b05d-d37e4234f3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.46 ms ± 32.8 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "5.42 ms ± 13.4 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "18.2 ms ± 116 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "6.8 ms ± 10.7 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Compare with pandas\n",
    "%timeit pdf[pdf.age > 65]\n",
    "%timeit gdf[gdf.age > 65]\n",
    "%timeit pdf.groupby(pdf.age // 10).income.mean()\n",
    "%timeit gdf.groupby('age_decade').income.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d4251f-316a-47b6-a044-417e76739d03",
   "metadata": {},
   "source": [
    "#### Using cuML (GPU Machine Learning)\n",
    "\n",
    "After data preparation with cuDF, you might want to perform machine learning or analytics on the data. This is where cuML comes in. cuML provides GPU implementations of many machine learning algorithms with an API that closely mirrors scikit-learn. This design lets you often just swap out sklearn for cuml and get an accelerated version of the algorithm. Supported algorithms include linear regression, logistic regression, ridge regression, K-Means clustering, DBSCAN, PCA, t-SNE, UMAP, random forest, gradient boosting, and more. Many algorithms in cuML can accept input as cuDF DataFrames or CuPy arrays, and will output results as cuDF/CuPy, ensuring the data stays on GPU through the pipeline.\n",
    "\n",
    "Let’s do a simple example: K-Means clustering on a set of points. We will generate a synthetic dataset of points on the GPU (using CuPy) and then use cuML’s KMeans to cluster them. Finally, we’ll compare the result with CPU scikit-learn KMeans on a smaller sample (for validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2f7b20-3169-443c-9c64-af2a15f9d095",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef8f5eae-37df-4dc4-8341-cff94c48cd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 predicted cluster labels (GPU): [1 2 1 2 2 2 1 1 1 0]\n",
      "GPU cluster centers:\n",
      " [[-4.6802746e-04  4.9970641e+00]\n",
      " [ 8.1728620e-04 -3.5804582e-03]\n",
      " [ 4.9998760e+00  5.0027781e+00]]\n",
      "CPU cluster centers (approx, on subset):\n",
      " [[-0.00886273  5.002054  ]\n",
      " [ 5.005546    4.997921  ]\n",
      " [-0.00847459 -0.01666689]]\n"
     ]
    }
   ],
   "source": [
    "from cuml.cluster import KMeans\n",
    "from sklearn.cluster import KMeans as skKMeans\n",
    "import cupy as cp\n",
    "\n",
    "# Generate synthetic data: 100,000 points in 2D forming 3 clusters\n",
    "# We'll sample points around three centers for clear clustering\n",
    "cp.random.seed(0)\n",
    "N = 100_000\n",
    "# Three cluster centers\n",
    "centers = cp.array([[0,0], [5,5], [0,5]], dtype=cp.float32)\n",
    "labels_true = cp.random.randint(0, 3, size=N)  # true cluster labels (random assignment)\n",
    "# Points = cluster center + some random noise\n",
    "points = centers[labels_true] + 0.5 * cp.random.randn(N, 2).astype(cp.float32)\n",
    "\n",
    "# GPU KMeans\n",
    "gpu_km = KMeans(n_clusters=3, max_iter=100)\n",
    "gpu_labels = gpu_km.fit_predict(points)\n",
    "print(\"First 10 predicted cluster labels (GPU):\", gpu_labels[:10])\n",
    "\n",
    "# (Optional) CPU KMeans on a subset to verify\n",
    "sample_points = cp.asnumpy(points[:5000])  # take 5000 points to CPU for quick check\n",
    "cpu_km = skKMeans(n_clusters=3, n_init='auto', max_iter=100, random_state=0)\n",
    "cpu_labels = cpu_km.fit_predict(sample_points)\n",
    "# Compare cluster centers (sort for matching order)\n",
    "print(\"GPU cluster centers:\\n\", cp.asnumpy(gpu_km.cluster_centers_))\n",
    "print(\"CPU cluster centers (approx, on subset):\\n\", cpu_km.cluster_centers_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c9916b-7350-4101-97dd-923dfb1c92af",
   "metadata": {},
   "source": [
    "### Task 3: Linear Regression using cuML. \n",
    "\n",
    "Suppose we want to fit a linear model:\n",
    "\n",
    "$$\n",
    "y = 3.5 \\cdot x_0 - 2.2 \\cdot x_1 + 1.0 + \\text{noise}\n",
    "$$\n",
    "\n",
    "Here, **3.5** and **-2.2** are the coefficients for the features \\(x_0\\) and \\(x_1\\), and **1.0** is the bias (the constant offset).\n",
    "\n",
    "1. Instantiate `LinearRegression` using `algorithm='svd'`\n",
    "2. Fit the model on `(X, y)`\n",
    "3. Retrieve and print the estimated coefficients and intercept/bias\n",
    "4. Compare them to the ground-truth values `[[3.5, -2.2], intercept=1.0]` (report absolute errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "161abf92-fd04-4d71-ae25-859366b2ec5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated coefficients (GPU): [ 3.5000002 -2.1999416]\n",
      "Estimated intercept (GPU): 0.9999674558639526\n"
     ]
    }
   ],
   "source": [
    "from cuml.linear_model import LinearRegression\n",
    "\n",
    "# Generate random data for linear regression: y = 3.5*x0 - 2.2*x1 + noise\n",
    "M, D = 500000, 2  # 500k samples, 2 features\n",
    "X = cp.random.rand(M, D, dtype=cp.float32)\n",
    "true_coeff = cp.array([3.5, -2.2], dtype=cp.float32)\n",
    "y = X.dot(true_coeff) + 1.0  # true bias = 1.0\n",
    "y += 0.01 * cp.random.randn(M, dtype=cp.float32)  # add some noise\n",
    "\n",
    "# Fit linear regression on GPU\n",
    "#ToDo\n",
    "\n",
    "# Print results\n",
    "print(\"Estimated coefficients (GPU):\", coef_gpu)\n",
    "print(\"Estimated intercept (GPU):\", intercept_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b0f054-ade3-48a8-9369-2e5d91f26341",
   "metadata": {},
   "source": [
    "### JAX: GPU-Accelerated Numerical Computing\n",
    "\n",
    "JAX is a Python library for accelerator-oriented numerical computing that brings high-performance, GPU/TPU-backed computation to familiar NumPy-like code. In a nutshell, JAX can be thought of as “NumPy on the CPU, GPU, and TPU” with support for automatic differentiation, making it popular in machine learning research. However, JAX’s capabilities go far beyond machine learning – it is equally useful for general-purpose numerical computing tasks in scientific computing and HPC contexts. With JAX, you write ordinary Python functions using jax.numpy (which mirrors the NumPy API) and get GPU-accelerated execution for free. If a GPU (or other accelerator) is available on your system, JAX will find it and by default allocate arrays and run computations on the GPU. This allows developers and researchers to write code once and have it run efficiently on CPUs or GPUs without specialized GPU programming.\n",
    "\n",
    "We can go back to our day 1 tutorial on JAX and just update the JAX installation to include CUDA. Once done, we have free CUDA execution integrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49fb271-bc56-4bff-90e1-6e010b2a7965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hpcp]",
   "language": "python",
   "name": "conda-env-hpcp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
