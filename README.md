# High Performance Computing in Practice - HS25
Welcome to the HPCP block module! This repository is organized to mirror the course structure, with a dedicated directory for each day.

This summer school targets advanced students and researchers seeking a hands-on introduction to modern High Performance Computing (HPC) methods. The course consists of four full-day modules:

- **Day 1 – From vanilla Python to HPC Python:**  
    Explore high-performance Python computing using numpy, numba, jax, and Python C/C++ bindings. Learn about JIT compilation, automatic differentiation, efficient memory access, and performance analysis fundamentals.

    | 25.08.2025 | @FHNW Building 6 - 6.0D13 |
    | -------- | ------- |
    |  09:15 |  Entry test (only for FHNW students) | 
    |  09:50 |  Welcome to HPCP (SM) |
    |  10:00 |  Numpy (MS) |
    |  11:00 |  Break | 
    |  11:15 |  Numpy (MS) | 
    |  12:00 |  Numpy (MS) |   
    |  13:00 |  Lunch |  
    |  14:00 |  JAX (MS) |  
    |  15:00 |  Numba (MS) |  
    |  16:00 |  Break | 
    |  16:15 |  Numba (MS) |  
    |  17:00 |  Python Bindings (MS)  | 

- **Day 2 – Using GPUs to accelerate your code:**  
    Learn the basics of GPU programming with numba.cuda, develop and optimize custom GPU kernels, and get an overview of the CUDA ecosystem and GPU profiling.

    | 26.08.2025 | @FHNW Building 6 - 6.0D13 |
    | -------- | ------- |
    |  09:15 |  Numba CUDA Basics (SM) | 
    |  10:00 |  Numba CUDA Basics (SM) | 
    |  11:00 |  Break | 
    |  11:15 |  Matrix Multiply in the Roofline Model (SM) | 
    |  12:00 |  Matrix Multiply in the Roofline Model (SM) |   
    |  13:00 |  Lunch |  
    |  14:00 |  Talk: Fast feedback indexer (HC) |  
    |  15:00 |  Python CUDA Ecosystem |  
    |  16:00 |  Break | 
    |  16:15 |  Python CUDA Ecosystem |  
    |  17:40 |  Wrap-Up  | 
    |  18:00 |  Apéro together with new AI&HPC students  | 

- **Day 3 – Cluster 101:**  
    Get introduced to HPC cluster environments, job submission with Slurm, module systems, parallel programming with MPI (via mpi4py), and initial performance analysis of multi-process workloads.

    | 01.09.2025 | @PSI Bildungszentrum |
    | -------- | ------- |
    |  09:15 |  HPC cluster 101 (MC) | 
    |  10:00 |  HPC cluster 101 (MC) | 
    |  11:00 |  Break | 
    |  11:15 |  How to use Slurm (HC) | 
    |  12:00 |  Talk: PSI SDSC |   
    |  13:00 |  Lunch |  
    |  14:00 |  MPI4PY (AS) |  
    |  15:00 |  MPI4PY (AS) |  
    |  16:00 |  Break | 
    |  16:15 |  MPI4PY (AS) |  
    |  17:00 |  Guided Tour | 


- **Day 4 – Advanced HPC usage:**  
    Delve into advanced parallel programming with MPI and GPUs, tackle challenges with shared HPC file systems, and study a real-world application: HPC in the ESA Euclid space mission.

    | 02.09.2025 | @PSI Bildungszentrum |
    | -------- | ------- |
    |  09:15 |  Dask (SM?) | 
    |  10:00 |  Dask (SM?) | 
    |  11:00 |  Break | 
    |  11:15 |  Multi-GPU and MPI (SM) | 
    |  12:00 |  Student Project (SM) |   
    |  13:00 |  Lunch |  
    |  14:00 |  Talk: Euclid HPC framework (SM) |  
    |  15:00 |  Shared File Systems (SM) |  
    |  16:00 |  Break | 
    |  16:15 |  Shared File Systems (SM) |  
    |  17:00 |  Wrap-Up | 



All modules use Python and interactive Jupyter notebooks for practical, hands-on learning.
