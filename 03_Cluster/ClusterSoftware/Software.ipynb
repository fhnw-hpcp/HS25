{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3d4ef75",
   "metadata": {},
   "source": [
    "# Cluster (Merlin6) Software\n",
    "\n",
    "All clusters need some way to be accessed, provide common software, and launching compute jobs in a coordinated fashion. We'll look at what [Merlin6](https://hpce.pages.psi.ch/merlin6/introduction.html) provides.\n",
    "\n",
    "## Cluster Access\n",
    "\n",
    "For cluster access, an account with proper credentials and authorization is needed.\n",
    "\n",
    "* **ssh** access to the login nodes. ssh is also possible to allocated nodes (see below - batch system)\n",
    "* **Remote desktop**, in this case NoMachine nxplayer, for graphical access.\n",
    "* **jupyterhub** for [interactive Python sessions](https://merlin-jupyter.psi.ch:8000).\n",
    "\n",
    "## Envrironment Modules\n",
    "\n",
    "We've seen, that especially lower level software needs to be compiled with support for system performance features. System administrators know the hardware and provide kernel drivers and specialized libraries either directly as system packages (if there is only one choice), or as environment **pmodules** (if there's a choice). Environment modules do little more than setting appropriate Linux environment variables for using installed software."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fd8243",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "* **NOTE I**: The following should work, when logging in via `ssh -Y <username>@merlin-l-002.psi.ch`\n",
    "* **NOTE II**: On the JupyterHub console, X11 is not working, and `srun --options..` should be left away or, if possible, replaced by `salloc --options..`\n",
    "* **NOTE III**: Inside a notebook the `! command` will run on a virgin shell lacking the module system environment and such. If this is a problem, use `! . ~/.bashrc; command`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77aad96d",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Documentation\n",
    "# module --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "212b257a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# List software\n",
    "# Only software above the current hierarchy is shown\n",
    "# Hierarchy: Compiler -> MPI -> MPI Specific\n",
    "# module avail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d148c97",
   "metadata": {},
   "source": [
    "The general idea behind *pmodule* is to limit output to software that is compiled with a certain compiler and MPI version.\n",
    "\n",
    "* First compilers are shown. Selecting one.\n",
    "* Then MPI versions are shown as well. Select one.\n",
    "* MPI specific software is shown as well.\n",
    "\n",
    "Dependencies are a bit too complex to always fit into this scheme, but as a guideline this should help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a52fe825",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Search for software\n",
    "# module search openmpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "726e8e66",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Include only lightly tested newer software\n",
    "# module use unstable\n",
    "# module search openmpi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c13c947",
   "metadata": {},
   "source": [
    "Sysadmins install software into a certain location on disk. To use it, environment variables like *PATH* have to be set. You could do it by hand, *pmodule* just simplifies the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21790b51",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Show environment changes\n",
    "# module show gcc/14.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebf62068",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Execute environment changes\n",
    "# module add gcc/14.2.0\n",
    "# which gcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2068ddd7",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# List added modules\n",
    "# module list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7579413a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Reset pmodule managed environment\n",
    "# module purge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abcc9fb",
   "metadata": {},
   "source": [
    "For Python, the *anaconda* module is provided, together with some preinstalled environments. (**ATTENTION**: by itself, the PSI anaconda modue only provides the *python3* executable, not *python*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37e03769",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# module add anaconda\n",
    "\n",
    "# Show existing conda envs\n",
    "# conda env list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ac67b5",
   "metadata": {},
   "source": [
    "## MPI Overview\n",
    "\n",
    "MPI ([Message Passing Interface](https://www.mpi-forum.org/)) is the most widely used standard for distributed and parallel computing on HPC clusters. MPI standardizes collaboration through communicator objects between processes that run in parallel on one or on separate compute nodes. We'll focus on MPI 5.0 and the world model (there's also the session model) that predefines the `MPI_COMM_WORLD` communicator object. This object is comprised of all processes. Processes are numbered sequentially by *rank*, starting with 0.\n",
    "\n",
    "Several implementations of MPI exist. OpenMPI, MPICH, and MVAPICH are well known, vendor based implementations usually are specializations of these - Intel MPI, Cray MPI, ... I'll focus on [OpenMPI](https://www.open-mpi.org) here whenever implementation details become important.\n",
    "\n",
    "Communicator objects come in two flavours. The first, like *MPI_COMM_WORLD*, are intra-communicators used to communicate between the processes in a group. The second, inter-communicators, are for communicating between two distinct groups of processes. In the following, we'll focus on intra-communicators.\n",
    "\n",
    "Intra-communicator objects are associated with\n",
    "\n",
    "* *context* for communication (e.g. messages within a context are ordered according to some rules)\n",
    "   * messages sent from one rank to another one are received in the order they were sent\n",
    "* *group* of processes, ordered by sequentially increasing integer *rank* (starting with 0)\n",
    "   * groups with the same processes, but different ordering, are not exactly equal\n",
    "* *topology*, virtual neighborhood information\n",
    "   * like cartesian, or graph topologies\n",
    "   * topologies map ranks to coordinates or graph vertices\n",
    "* *attributes*, (tag, value) pairs, for additional info\n",
    "   * e.g. *MPI_COMM_WORLD* has the *MPI_TAG_UB* attribute (upper bound for tags)\n",
    "* *error handler*\n",
    "   * by default, predefined *MPI_ERRORS_ARE_FATAL* handler is set\n",
    "   * the predefined *MPI_ERRORS_RETURN* handler can be set to handle errors in the code\n",
    "\n",
    "Communicators can be duplicated or split into subcommunicators with distinct groups in various ways. It's also possible to create new communicators specifying a group of processes. Different communicators can be used independently.\n",
    "\n",
    "The predefined intra-communicator `MPI_COMM_SELF` only has the local rank in the group.\n",
    "\n",
    "**Source and destination**\n",
    "\n",
    "If source or destination is needed, they are specified by the process rank. *MPI_ANY_SOURCE* accept incoming data from any rank. *MPI_PROC_NULL* is a dummy rank, that may be valid as source or destination. This might be useful to simplify the code.\n",
    "\n",
    "**Point to point communication**\n",
    "\n",
    "Send and receive commands will be seen in sending order on the receiver within a communication context. The datatypes must match on both sides. The receiver can specify a higher element count than the sender, but not vice versa.\n",
    "\n",
    "Send operations specify a destination (or *MPI_PROC_NULL*) rank and an integer tag. Receive operations specify the source (or *MPI_ANY_SOURCE*/*MPI_PROC_NULL*) and an integer tag (or *MPI_ANY_TAG*). The source and destination ranks and the tags must match.\n",
    "\n",
    "Receive operations have a status object output argument, it is filled with info on the number of transferred elements, the source rank, the tag, or an error on failure. *MPI_STATUS_IGNORE* may be given as argument if the status is unimportant.\n",
    "\n",
    "Send and receive exist in many different versions.\n",
    "\n",
    "| Mode        | Blocking | Non-blocking | Persistent |\n",
    "| ----------- | -------- | ------------ | ---------- |\n",
    "| Normal      |          | I            |   _init    |\n",
    "| Buffered    | B        | IB           | B _init    |\n",
    "| Synchronous | S        | IS           | S _init    |\n",
    "| Ready       | R        | IR           | R _init    |\n",
    "| Partitioned | -        | -            | P _init    |\n",
    "\n",
    "*Blocking*\n",
    "\n",
    "Sender waits until the send buffer can be used again. Receiver waits until the data is received.\n",
    "\n",
    "*Non-blocking*\n",
    "\n",
    "Start the opration in the background. Return a *request* object that **MUST** be queried for completion or waited for in order to finish the operation. Great for hiding communication.\n",
    "\n",
    "*Persistent*\n",
    "\n",
    "Prepare the communication operation and return a request object. The request can then be started later and repeatedly. After starting the operation, the request is used as in *non-blocking* communication. Might safe time if the same operation is done many times.\n",
    "\n",
    "*Modes*\n",
    "\n",
    "* *Normal*: The system decides how this is done\n",
    "* *Buffered*: Data is buffered. System sends data in the background.\n",
    "* *Synchronous*: Wait until receiver starts receiving and send buffer is no longer used.\n",
    "* *Ready*: Receiver **MUST** be ready before send. No buffering is allowed.\n",
    "* *Partitioned*: Send/receive data in chunks. Chunk size must not match.\n",
    "\n",
    "**Collective communication**\n",
    "\n",
    "Collective operations must be done by all ranks in the group associated with an intra-communicator. They exist in normal, non-blocking, and persisten variants.\n",
    "\n",
    "* *Barrier*: synchronization\n",
    "* *Broadcast*: one to all\n",
    "* *Gather*: all to one\n",
    "* *Scatter*: distribute content from one to all\n",
    "* *Allgather*: like *gather*, but all receive the result\n",
    "* *Alltoall*: all distribute content to all\n",
    "* *Reduction*: reduction from all to one\n",
    "   * maximum\n",
    "   * minimum\n",
    "   * sum\n",
    "   * product\n",
    "   * logical and\n",
    "   * bit-wise and\n",
    "   * logical or\n",
    "   * bit-wise or\n",
    "   * logical exclusive or (xor)\n",
    "   * bit-wise exclusive or (xor)\n",
    "   * max value and location\n",
    "   * min value and location\n",
    "* *Allreduce*: like *reduce*, but all receive the result\n",
    "* *Reduce-Scatter*: like *reduce*, but result is distributed to all\n",
    "* *Scan*: prefix reduction, rank *i* recives reduction result from rank *0...i*\n",
    "\n",
    "![Collectives](img/Collectives.png)\n",
    "\n",
    "**Virtual topologies**\n",
    "\n",
    "Create neighbourhood links and communicate with neighbours.\n",
    "\n",
    "* Create cartesian topology\n",
    "* Create graph topology\n",
    "* Neighbourhood gather\n",
    "* Neighbourhood alltoall\n",
    "\n",
    "**One sided communication**\n",
    "\n",
    "Remote memory window access and operations, separates communication from synchronization.\n",
    "\n",
    "* Read\n",
    "* Write\n",
    "* Accumulate\n",
    "* Read and update\n",
    "* Compare and swap\n",
    "* \n",
    "\n",
    "**Datatypes**\n",
    "\n",
    "You can create your own structured and array data types.\n",
    "\n",
    "**I/O**\n",
    "\n",
    "MPI supports parallel I/O. Libraries like HDF5 support MPI I/O.\n",
    "\n",
    "A file is abstracted as a view on a sequence of elementary data type. Both collective and individual access functions are standardized, as well as blocking and non-blocking file access.\n",
    "\n",
    "Depending on the underlying file system and implementation, MPI I/O supports\n",
    "\n",
    "* collective buffering: I/O is performed by a subset of compute nodes that collect smaller chunks into bigger ones\n",
    "* striped access: file is distributed to stripes on ditinct I/O devices to increase throughput\n",
    "* data access through chunks: like subarrays\n",
    "\n",
    "**Dynamic processes**\n",
    "\n",
    "Create new processes and communators for interacting with them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff529b4",
   "metadata": {},
   "source": [
    "## Data Catalog and Backup\n",
    "\n",
    "Scientists often produce large datasets. Sometimes these need to be transferred to or away from the cluster. Archiving for later retrieval and reexamination or verification of scientific results is also important. To facilitate retrieval, archived data is enriched with meta data thaht describes how data was produced and what it is about.\n",
    "\n",
    "* Data transfer from and to the cluster is supported at PSI via [Globus](https://www.globus.org/data-transfer).\n",
    "* Meta data enriched data archiving with [SciCat](https://github.com/SciCatProject)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
